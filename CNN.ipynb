{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFxb6a3OINVt",
        "colab_type": "text"
      },
      "source": [
        "# Drive Mounting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KxH1HjVItSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itjxMxU7JApb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd drive/\"My Drive\"/Pala_Project/Keras Network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WxCCUcmIDA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfywWbCxJcsj",
        "colab_type": "text"
      },
      "source": [
        "# Data Network Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CGYr1Yajm7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "''' **** Data Augmentation **** '''\n",
        "\n",
        "def flip_img(img, depth, traj):\n",
        "  flip_img = cv.flip(img, 1)\n",
        "  flip_depth = cv.flip(depth, 1)\n",
        "  flip_traj = [[IMAGE_WIDTH - 1 - x, y] for x, y in traj]\n",
        "  return flip_img, flip_depth, flip_traj\n",
        "\n",
        "def randomBrightness(img):\n",
        "  \n",
        "  # random.seed()\n",
        "  \n",
        "  dictForGenerator = {\"brightness\": random.uniform(0.4, 2)}\n",
        "  \n",
        "  img_gen = ImageDataGenerator()\n",
        "  img = img_gen.apply_transform(img, dictForGenerator)\n",
        "  \n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-p5ex7Aq2SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "def batch_generator(images_paths, trajectories, batch_size):\n",
        "    \"\"\"\n",
        "    Generate training images given image paths and associated images trajectories\n",
        "    \"\"\"\n",
        "    \n",
        "    # np.random.seed()\n",
        "    \n",
        "    images = np.zeros([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, 4]) # IMAGE_CHANNELS = 4 Channels (R, G, B, D)\n",
        "    # images = np.zeros([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, 3]) # IMAGE_CHANNELS = 3 Channels (R, G, B)\n",
        "    pos_vect = np.zeros([batch_size, 30, 2])\n",
        "    \n",
        "    while True:\n",
        "        i = 0\n",
        "        for index in np.random.permutation(images_paths.shape[0]):\n",
        "            image_path = images_paths[index][0]\n",
        "            depth_path = images_paths[index][1]\n",
        "            \n",
        "            img = cv.imread(image_path)\n",
        "            \n",
        "            depth = cv.imread(depth_path, -1)\n",
        "            depth[depth > 10000] = 10000\n",
        "            \n",
        "            traj = trajectories[index]\n",
        "            \n",
        "            # ********  START   Data Augmentation  ********\n",
        "            \n",
        "            if np.random.rand() < 0.5:\n",
        "              img, depth, traj = flip_img(img, depth, traj)\n",
        "            if np.random.rand() < 0.5:\n",
        "              img = randomBrightness(img)\n",
        "              \n",
        "            # ********  END     Data Augmentation  ********\n",
        "            \n",
        "            img = img / 127.5 - 1    # Normalizzazione tra [-1, 1]\n",
        "            depth = depth / 5000 - 1 # Normalizzazione tra [-1, 1]\n",
        "            \n",
        "            depth = np.reshape(depth, (IMAGE_HEIGHT, IMAGE_WIDTH, 1))\n",
        "            rgbd = np.concatenate((img, depth), axis=2)\n",
        "            # rgbd = img # NB: Se IMAGE_CHANNELS = 3\n",
        "            \n",
        "            images[i] = rgbd\n",
        "            pos_vect[i] = np.array(traj)\n",
        "            \n",
        "            i += 1\n",
        "            if i == batch_size:\n",
        "                break\n",
        "        yield images, pos_vect\n",
        "        # return images, pos_vect\n",
        "\n",
        "def load_data(train_csv = 'CSV/train_driving_log.csv', valid_csv = 'CSV/validation_driving_log.csv'):\n",
        "  train_data_df = pd.read_csv(train_csv, error_bad_lines=False)\n",
        "  valid_data_df = pd.read_csv(valid_csv, error_bad_lines=False)\n",
        "  \n",
        "  X_train = train_data_df[['image','depth']].values\n",
        "  X_valid = valid_data_df[['image','depth']].values\n",
        "  \n",
        "  y_train = train_data_df['trajectory'].values\n",
        "  y_train = [[[int(xy.split(',')[0]), int(xy.split(',')[1])] for xy in trajectory.split(':')] for trajectory in y_train]\n",
        "  \n",
        "  y_valid = valid_data_df['trajectory'].values\n",
        "  y_valid = [[[int(xy.split(',')[0]), int(xy.split(',')[1])] for xy in trajectory.split(':')] for trajectory in y_valid]\n",
        "  \n",
        "  return X_train, X_valid, y_train, y_valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvNWfiopQ5gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNbVsma_XzOR",
        "colab_type": "text"
      },
      "source": [
        "# Keras Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqkuDKBaX1zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras\n",
        "import keras\n",
        "keras.__version__\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Reshape\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWxBBiIqJIic",
        "colab_type": "text"
      },
      "source": [
        "# Definition and Training of a New Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1i4aFFQWfAf",
        "colab_type": "text"
      },
      "source": [
        "###Definition of a new Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0lFE5smtyQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 80, 160, 4 # IMAGE_CHANNELS = 4 Channels (R, G, B, D)\n",
        "# IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 80, 160, 3 # IMAGE_CHANNELS = 3 Channels (R, G, B)\n",
        "\n",
        "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(24, 5, 5, activation='elu', subsample=(2, 2), input_shape=INPUT_SHAPE))\n",
        "model.add(Conv2D(36, 5, 5, activation='elu', subsample=(2, 2)))\n",
        "model.add(Conv2D(48, 5, 5, activation='elu', subsample=(2, 2)))\n",
        "model.add(Conv2D(64, 3, 3, activation='elu'))\n",
        "model.add(Conv2D(64, 3, 3, activation='elu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(128, activation='elu'))\n",
        "model.add(Dense(60))\n",
        "model.add(Reshape((30,2)))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p46PmLkTfAb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model scheme with shapes\n",
        "\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWPzLsk9VGsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('SavedModel4/saved_model{epoch:03d}.h5', # SavedModel{n}/...\n",
        "                              monitor='val_loss',\n",
        "                              verbose=0,\n",
        "                              save_best_only=False,\n",
        "                              mode='auto',\n",
        "                              period=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmynHq6uVbLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mean_squared_error', optimizer=Adam(lr=1.0e-4), metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cszBRYH2W4xa",
        "colab_type": "text"
      },
      "source": [
        "###Training Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aApz8DqBW3VK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def roundup(x):\n",
        "    return int(math.ceil(x / 10.0)) * 10\n",
        "\n",
        "def scheduler(epoch):\n",
        "    lr = K.get_value(model.optimizer.lr)\n",
        "    if (epoch + 1) % 50 == 0: # Ogni 50 epoche dimezzo il learning-rate\n",
        "        K.set_value(model.optimizer.lr, lr/2)\n",
        "        lr = K.get_value(model.optimizer.lr) # Nuovo valore del learning rate\n",
        "        print('*** NUOVO LEARNING RATE: {lr_value} ***'.format(lr_value=lr))\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGErSjyqVben",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "change_lr = LearningRateScheduler(scheduler)\n",
        "\n",
        "bs = 20\n",
        "\n",
        "history = model.fit_generator(batch_generator(X_train, y_train, bs),\n",
        "                    steps_per_epoch=roundup(len(X_train)/bs),\n",
        "                    epochs=200,\n",
        "                    max_q_size=20,\n",
        "                    validation_data=batch_generator(X_valid, y_valid, bs),\n",
        "                    nb_val_samples=roundup(len(X_valid)/bs),\n",
        "                    callbacks=[checkpoint, change_lr],\n",
        "                  \tworkers=10,\n",
        "\t\t\t              use_multiprocessing=True,\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNWyovw8T6t4",
        "colab_type": "text"
      },
      "source": [
        "# Resume Training from checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNLtQq8cYac0",
        "colab_type": "text"
      },
      "source": [
        "### Loading existing Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOC4Zxm4UHs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 80, 160, 4 # IMAGE_CHANNELS = 4 Channels (R, G, B, D)\n",
        "# IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 80, 160, 3 # IMAGE_CHANNELS = 3 Channels (R, G, B)\n",
        "\n",
        "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
        "\n",
        "model = load_model('SavedModel4/saved_model100.h5') # SavedModel{n}/...\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PrNi6doUMSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('SavedModel4/saved_model{epoch:03d}.h5', # SavedModel{n}/...\n",
        "                              monitor='val_loss',\n",
        "                              verbose=0,\n",
        "                              save_best_only=False,\n",
        "                              mode='auto',\n",
        "                              period=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slYv0vnuUWk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mean_squared_error', optimizer=Adam(lr=(1.0e-4)/8), metrics=['mae']) #NB: Mettere un lr coerente con l'ultimo utilizzato dalla rete prima di interrompere il training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiZ5Sy9iJsQF",
        "colab_type": "text"
      },
      "source": [
        "### Training Phase Resume"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4cRik7BPFne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def roundup(x):\n",
        "    return int(math.ceil(x / 10.0)) * 10\n",
        "\n",
        "def scheduler(epoch):\n",
        "    lr = K.get_value(model.optimizer.lr)\n",
        "    if (epoch + 1) % 50 == 0: # Ogni 50 epoche dimezzo il learning-rate\n",
        "        K.set_value(model.optimizer.lr, lr/2)\n",
        "        lr = K.get_value(model.optimizer.lr) # Nuovo valore del learning rate\n",
        "        print('*** NUOVO LEARNING RATE: {lr_value} ***'.format(lr_value=lr))\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk9RKU_r0o_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "change_lr = LearningRateScheduler(scheduler)\n",
        "\n",
        "bs=20\n",
        "\n",
        "history = model.fit_generator(batch_generator(X_train, y_train, bs),\n",
        "                    steps_per_epoch=roundup(len(X_train)/bs),\n",
        "                    epochs=200,\n",
        "                    max_q_size=20,\n",
        "                    validation_data=batch_generator(X_valid, y_valid, bs),\n",
        "                    nb_val_samples=roundup(len(X_valid)/bs),\n",
        "                    callbacks=[checkpoint, change_lr],\n",
        "                  \tworkers=10,\n",
        "\t\t\t              use_multiprocessing=True,\n",
        "                    initial_epoch=100, # NB: Se ha salvato fino a N, mettere N\n",
        "                    verbose=1,)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgTvOC0L5Ebz",
        "colab_type": "text"
      },
      "source": [
        "# Loss and MAE Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUptUIv6d1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(history.history.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf_wiFAv5TRi",
        "colab_type": "text"
      },
      "source": [
        "#### Loss Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aw0ecVD2-rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc = 'upper left')\n",
        "\n",
        "''' # Per Stampare con i corretti valori dell'asse-x quando salta la connessione\n",
        "curr_x =    [  0,  20,  40,  60,  80, 100]\n",
        "my_xticks = [100, 120, 140, 160, 180, 200]\n",
        "plt.xticks(curr_x, my_xticks)\n",
        "'''\n",
        "\n",
        "# plt.savefig('loss4.pdf') # loss{n}.pdf\n",
        "plt.savefig('loss4.png') # loss{n}.png\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ait34v7c5XtW",
        "colab_type": "text"
      },
      "source": [
        "#### MAE Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PljIW4og4sm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['mean_absolute_error'])\n",
        "plt.plot(history.history['val_mean_absolute_error'])\n",
        "plt.title('model mean_absolute_error')\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc = 'upper left')\n",
        "\n",
        "''' # Per Stampare con i corretti valori dell'asse-x quando salta la connessione\n",
        "curr_x =    [  0,  20,  40,  60,  80, 100]\n",
        "my_xticks = [100, 120, 140, 160, 180, 200]\n",
        "plt.xticks(curr_x, my_xticks)\n",
        "'''\n",
        "\n",
        "# plt.savefig('mae.4pdf') # mae{n}.pdf\n",
        "plt.savefig('mae2.png') # mae{n}.png\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEKZvB2BBt0l",
        "colab_type": "text"
      },
      "source": [
        "# Validation Phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUCgbiAW-d0p",
        "colab_type": "text"
      },
      "source": [
        "#### evaluate_generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUuXV73KB3ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def roundup(x):\n",
        "    return int(math.ceil(x / 10.0)) * 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_rI8lvDBwOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 20\n",
        "\n",
        "model = load_model('SavedModel4/saved_model100.h5') # SavedModel{n}/...\n",
        "\n",
        "scores = model.evaluate_generator(batch_generator(X_valid, y_valid, bs),\n",
        "                                  # steps = roundup(len(X_valid)/bs),\n",
        "                                  steps=5,\n",
        "                                  max_queue_size=10,\n",
        "                                  verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyNLhIusCBkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOnEjBVU-kGa",
        "colab_type": "text"
      },
      "source": [
        "#### evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbeRI9xz9tQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 20\n",
        "\n",
        "model = load_model('SavedModel4/saved_model100.h5') # SavedModel{n}/...\n",
        "\n",
        "x, y = batch_generator(X_valid, y_valid, bs) # NB: Cambiare 'yield' con 'return' in batch_generator\n",
        "\n",
        "scores = model.evaluate(x, y, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JoXjAzb8Los",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyCa6A7lJxhx",
        "colab_type": "text"
      },
      "source": [
        "# Testing Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c2Qw1hhAbeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVs7WoX5N7Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 80, 160, 4      # IMAGE_CHANNELS = 4 Channels (R, G, B, D)\n",
        "# IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 80, 160, 3    # IMAGE_CHANNELS = 3 Channels (R, G, B)\n",
        "\n",
        "n_seq = str(16) # str(17)\n",
        "imgs_path   = 'Dataset/IMG/test/seq{n}/left/'.format(n=n_seq)\n",
        "depths_path = 'Dataset/IMG/test/seq{n}/depth/'.format(n=n_seq)\n",
        "# imgs_path   = '* Test */test/seq{n}/left/'.format(n=n_seq)\n",
        "# depths_path = '* Test */test_flip/seq{n}/depth/'.format(n=n_seq)\n",
        "\n",
        "images_list = [img   for img   in sorted(os.listdir(imgs_path))   if img.endswith('.png')]\n",
        "depths_list = [depth for depth in sorted(os.listdir(depths_path)) if depth.endswith('.png')]\n",
        "\n",
        "images_list[0:250] = [] # Tolgo i primi 250 elementi\n",
        "depths_list[0:250] = [] # Tolgo i primi 250 elementi\n",
        "\n",
        "print(images_list)\n",
        "\n",
        "imgs = []\n",
        "depths = []\n",
        "\n",
        "for image_name in images_list:\n",
        "  img = cv.imread(imgs_path + image_name)\n",
        "  img = img / 127.5 - 1\n",
        "  imgs.append(img)  \n",
        "  print('Image: ', image_name)\n",
        "\n",
        "for image_name in depths_list:\n",
        "  depth = cv.imread(depths_path + image_name, -1)\n",
        "  depth = np.reshape(depth, (IMAGE_HEIGHT, IMAGE_WIDTH, 1))\n",
        "  depth[depth > 10000] = 10000\n",
        "  depth = depth / 5000 - 1\n",
        "  depths.append(depth)\n",
        "  print('Depth: ', image_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1PZpDJtOE3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 80, 160, 4 # IMAGE_CHANNELS = 4 Channels (R, G, B, D)\n",
        "# IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 80, 160, 3 # IMAGE_CHANNELS = 3 Channels (R, G, B)\n",
        "\n",
        "dim = len(images_list)\n",
        "images = np.zeros([dim, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
        "\n",
        "for i, img in enumerate(imgs):\n",
        "  images[i] = np.concatenate((img, depths[i]), axis=2) # Se IMAGE_CHANNELS = 4\n",
        "  # images[i] = img # Se IMAGE_CHANNELS = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmn2mRzQb8RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "import json\n",
        "\n",
        "epochs = ['050', '070', '100', '150', '200']\n",
        "# models = ['3', '3*', '4', '4*']\n",
        "# models = ['3']\n",
        "models = ['4']\n",
        "\n",
        "for n_mod in models:\n",
        "  for n_epoch in epochs:\n",
        "    model = load_model('SavedModel{mod}/saved_model{epoch}.h5'.format(mod=n_mod, epoch=n_epoch))\n",
        "    prediction = model.predict(images)\n",
        "    print('*** Prediction Shape: ***', prediction.shape, 'Model {mod}_ep{ep}'.format(mod = n_mod, ep=n_epoch))\n",
        "\n",
        "    file = '#{mod} prediction_seq{n}_ep{epoch}.json'.format(mod=n_mod, n=n_seq, epoch=n_epoch)\n",
        "    with open(file, 'w') as f:\n",
        "      json.dump(prediction.tolist(), f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW0-wFFPBwpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVy6PnTWgrhS",
        "colab_type": "text"
      },
      "source": [
        "# Part of Notebook Reserved for Saving Images for the Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EdaIMz-Safy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, json, random\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def resize(img):\n",
        "  SCALE_PERCENT = 0.125\n",
        "  height = img.shape[0]\n",
        "  width = img.shape[1]\n",
        "  new_width = int(width * SCALE_PERCENT)\n",
        "  new_height = int(height * SCALE_PERCENT)\n",
        "  dim = (new_width, new_height) # (1280, 640) -> (160, 80)\n",
        "  resized = cv.resize(img, dim, interpolation=cv.INTER_AREA)\n",
        "  return resized\n",
        "\n",
        "def flip_img(img, depth, traj):\n",
        "  IMAGE_WIDTH = 160\n",
        "  flip_img = cv.flip(img, 1)\n",
        "  flip_depth = cv.flip(depth, 1)\n",
        "  flip_traj = np.array([[IMAGE_WIDTH - 1 - x, y] for x, y in traj])\n",
        "  return flip_img, flip_depth, flip_traj\n",
        "\n",
        "def randomBrightness(img):\n",
        "  # random.seed()\n",
        "  dictForGenerator = {\"brightness\": 0.4} # random.uniform(0.4, 2)}\n",
        "  img_gen = ImageDataGenerator()\n",
        "  img = img_gen.apply_transform(img, dictForGenerator)\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0juct7Afgr99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveExamplesOfImages(image_path, depth_path, trajectories_path):\n",
        "    \n",
        "    num_of_points = 30\n",
        "    \n",
        "    with open(trajectories_path) as json_file:\n",
        "        data = json.load(json_file)\n",
        "\n",
        "    original_image = cv.imread(image_path)\n",
        "    original_depth = cv.imread(depth_path, -1)\n",
        "    new_depth = np.array(original_depth)\n",
        "    new_depth[new_depth > 10000] = 10000\n",
        "    \n",
        "    n_frame = int(image_path.split('/')[-1][-10:-4]) - 1\n",
        "    frame = 'frame_{n}'.format(n='0' * (6 - len(str(n_frame))) + str(n_frame))\n",
        "\n",
        "    coorFuture = data[frame][\"object_0\"][\"future\"]\n",
        "    coorFuture = coorFuture[0:num_of_points] if len(coorFuture) >= num_of_points else coorFuture # Vengono mostrati solo i primi 30 punti\n",
        "          \n",
        "    for i, item in enumerate(coorFuture):\n",
        "      y = int(item[1])\n",
        "      x = int(item[0])\n",
        "\n",
        "      cv.circle(original_image, (x, y), 3, (0, 255, 0), 2)\n",
        "    \n",
        "    cv.imwrite('ReportImages/DS/Image/original_image.png', original_image)\n",
        "    cv.imwrite('ReportImages/DS/Depth/original_depth.png', original_depth)\n",
        "    cv.imwrite('ReportImages/DS/Depth/new_depth.png', new_depth)\n",
        "    cv.imwrite('ReportImages/DS/Image/cropped_image.png', original_image[60:-20, :, :])\n",
        "    cv.imwrite('ReportImages/DS/Depth/cropped_depth.png', original_depth[60:-20, :])\n",
        "    cv.imwrite('ReportImages/DS/Depth/cropped_new_depth.png', new_depth[60:-20, :])\n",
        "    cv.imwrite('ReportImages/DS/Image/small_image.png', resize(original_image[60:-20, :, :]))\n",
        "    cv.imwrite('ReportImages/DS/Depth/small_depth.png', resize(original_depth[60:-20, :]))\n",
        "    \n",
        "    small_new_depth = resize(original_depth[60:-20, :])\n",
        "    small_new_depth[small_new_depth > 10000] = 10000\n",
        "    cv.imwrite('ReportImages/DS/Depth/small_new_depth.png', small_new_depth)\n",
        "    # cv.imwrite('ReportImages/DS/Depth/small_new_depth.png', resize(new_depth[60:-20, :]))\n",
        "    \n",
        "    cv.destroyAllWindows()  # Deallocating memories taken for window creation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N81HeXt8TmVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveDataAugmentation(image_path, depth_path, trajectories_path):\n",
        "    \n",
        "    num_of_points = 30\n",
        "    \n",
        "    with open(trajectories_path) as json_file:\n",
        "        data = json.load(json_file)\n",
        "\n",
        "    n_frame = int(image_path.split('/')[-1][-10:-4]) - 1\n",
        "    frame = 'frame_{n}'.format(n='0' * (6 - len(str(n_frame))) + str(n_frame))\n",
        "    \n",
        "    small_image = cv.imread(image_path)\n",
        "    small_depth = cv.imread(depth_path, -1)\n",
        "    small_new_depth = np.array(small_depth)\n",
        "    small_new_depth[small_new_depth > 10000] = 10000\n",
        "     \n",
        "\n",
        "    coorFuture = data[frame][\"object_0\"][\"future\"]\n",
        "    coorFuture = coorFuture[0:num_of_points] if len(coorFuture) >= num_of_points else coorFuture # Vengono mostrati solo i primi 30 punti\n",
        "    \n",
        "    flip_small_image, flip_small_new_depth, flip_coorFuture = flip_img(small_image, small_new_depth, coorFuture)\n",
        "    \n",
        "    rb_small_image = randomBrightness(small_image)\n",
        "    rb_flip_small_image = randomBrightness(flip_small_image)\n",
        "    \n",
        "    for i, item in enumerate(coorFuture):\n",
        "      x = int(item[0])\n",
        "      y = int(item[1])\n",
        "      \n",
        "      flip_x = flip_coorFuture[i][0]\n",
        "      flip_y = flip_coorFuture[i][1]\n",
        "      \n",
        "      small_image[y, x] = [0, 255, 0]\n",
        "      rb_small_image[y, x] = [0, 255, 0]\n",
        "      flip_small_image[flip_y, flip_x] = [0, 255, 0]\n",
        "      rb_flip_small_image[flip_y, flip_x] = [0, 255, 0]\n",
        "      \n",
        "    cv.imwrite('ReportImages/DA/Image/small_image.png', small_image)\n",
        "    cv.imwrite('ReportImages/DA/Image/rb_small_image.png', rb_small_image)\n",
        "    cv.imwrite('ReportImages/DA/Image/flip_small_image.png', flip_small_image)\n",
        "    cv.imwrite('ReportImages/DA/Image/rb_flip_small_image.png', rb_flip_small_image)\n",
        "    cv.imwrite('ReportImages/DA/Depth/small_depth.png', small_depth)\n",
        "    cv.imwrite('ReportImages/DA/Depth/flip_small_depth.png', cv.flip(small_depth, 1))\n",
        "    cv.imwrite('ReportImages/DA/Depth/small_new_depth.png', small_new_depth)\n",
        "    cv.imwrite('ReportImages/DA/Depth/flip_small_new_depth.png', flip_small_new_depth)\n",
        "    cv.destroyAllWindows()  # Deallocating memories taken for window creation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhwImvy0gti1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMMAGINI ORIGINALI\n",
        "realTrajs_json = 'Sequenze-Depth-RGB/seq1/trajectories.json'\n",
        "image = 'Sequenze-Depth-RGB/seq1/left/left001000.png'\n",
        "depth = 'Sequenze-Depth-RGB/seq1/depth/depth001000.png'\n",
        "\n",
        "# saveExamplesOfImages(image, depth, realTrajs_json)\n",
        "\n",
        "# IMMAGINI PICCOLE\n",
        "realTrajs_json = 'Dataset/IMG/train/seq1/trajectories.json'\n",
        "image = 'Dataset/IMG/train/seq1/left/left001000.png'\n",
        "depth = 'Dataset/IMG/train/seq1/depth/depth001000.png'\n",
        "\n",
        "saveDataAugmentation(image, depth, realTrajs_json)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ApVdLbC3ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs_input = '* Test */test_flip/seq17/left/'\n",
        "\n",
        "for image in sorted(os.listdir(imgs_input)):\n",
        "  if (image.endswith('png')):  # Controlla che si tratti di un'immagine\n",
        "    print(image)\n",
        "    img = cv.imread(imgs_input + '{img_name}'.format(img_name=image), cv.IMREAD_UNCHANGED)\n",
        "    img = randomBrightness(img)\n",
        "    cv.imwrite('* Test */test/seq17/left/' + image, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dk4IMGPE9YE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path = 'Sequenze-Depth-RGB/seq16/left/'\n",
        "path = 'Sequenze-Depth-RGB/seq17/left/'\n",
        "\n",
        "for i, image in enumerate(sorted(os.listdir(path))):\n",
        "  if (image.endswith('png') and i == 1000):  # Controlla che si tratti di un'immagine\n",
        "    print(image)\n",
        "    img = cv.imread(path + '{img_name}'.format(img_name=image), cv.IMREAD_UNCHANGED)\n",
        "    img = randomBrightness(img)\n",
        "    img = cv.flip(img, 1)\n",
        "    cv.imwrite(image, img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}